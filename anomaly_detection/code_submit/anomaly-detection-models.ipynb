{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Libraries and Requirments","metadata":{}},{"cell_type":"code","source":"import pathlib\nfrom typing import Any, Optional\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport tensorflow as tf\nimport keras\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.layers import Dense, InputLayer, Dropout\nfrom kerastuner.tuners import RandomSearch\nimport tensorflow_probability as tfp\nfrom tensorflow_probability import distributions as tfd\nfrom sklearn.model_selection import train_test_split\nfrom keras import backend as K\nfrom sklearn.preprocessing import OneHotEncoder\n!pip install siuba # R syntax for python. Mainly the '>>' operator to work with plotnine\nfrom siuba import *\nfrom plotnine import * # ggplot for python\nimport itertools\nfrom itertools import chain # for avoiding lists\nimport math # for sqrt()\nimport shap\n\nprint(\"Tensorflow version:\", tf.__version__)\ntf.get_logger().setLevel('ERROR')\nprint(0)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-02T11:19:23.714004Z","iopub.execute_input":"2021-07-02T11:19:23.71454Z","iopub.status.idle":"2021-07-02T11:19:46.109986Z","shell.execute_reply.started":"2021-07-02T11:19:23.71445Z","shell.execute_reply":"2021-07-02T11:19:46.109304Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Helper functions","metadata":{}},{"cell_type":"code","source":"# helper function to plot the history of the dataframe\ndef plot_history(hist: pd.DataFrame, title=\"History\", file_title=\"\") -> None:\n    plt.figure()\n    plt.xlabel('Epoch')\n    plt.ylabel('Accuracy')\n    plt.plot(hist['epoch'], hist['accuracy'],\n           label='Train Accuracy')\n    plt.plot(hist['epoch'], hist['val_accuracy'], alpha=0.5,\n           label = 'Validation Accuracy')\n    plt.legend()\n    plt.title(title)\n    plt.savefig(file_title, dpi=500)\n    plt.show()\n    # plt.figure()\n    # plt.xlabel('Epoch')\n    # plt.ylabel('Mean Square Error')\n    # plt.plot(hist['epoch'], hist['mse'],\n    #        label='Train Error')\n    # plt.plot(hist['epoch'], hist['val_mse'],\n    #        label = 'Val Error')\n    # plt.legend()\n    # plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-02T11:19:46.111107Z","iopub.execute_input":"2021-07-02T11:19:46.111468Z","iopub.status.idle":"2021-07-02T11:19:46.116639Z","shell.execute_reply.started":"2021-07-02T11:19:46.111441Z","shell.execute_reply":"2021-07-02T11:19:46.11603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" def plot_confusion_matrix(cm, class_labels=None, file_title=\"\"):\n    # From DME labs\n    \"\"\"Plots a confusion matrix using seaborn's heatmap function\n    \n    Columns and rows are labelled with the strings provided in class_labels.\n    \n    Parameters\n    ----------\n    cm: array-like\n        contains the confusion matrix\n        \n    class_labels: array-like, optional\n        contains the string labels\n            \n    \"\"\"\n    # check whether we have count data or not\n    if issubclass(cm.dtype.type, np.integer):\n        fmt = 'd'\n    else:\n        fmt = '.2f'\n    \n    # Your code goes here\n    \n    if class_labels is not None:\n        sns.heatmap(cm, cmap='viridis',xticklabels=class_labels, yticklabels=class_labels,\\\n                    annot=True, annot_kws={\"fontsize\":9},  fmt=fmt)  # controls the display of the numbers\n    else:\n        sns.heatmap(cm, annot=True, annot_kws={\"fontsize\":9},  fmt=fmt)\n        \n    plt.ylabel('True label', fontweight='bold')\n    plt.xlabel('Predicted label', fontweight='bold')\n    \n    # you can change the appearance of the figure with lower-level matplotlib commands\n    # here we rotate the labels on the x-axis\n    plt.setp(plt.gca().get_xticklabels(), ha=\"right\", rotation_mode=\"anchor\")\n    plt.savefig(file_title, dpi=500)","metadata":{"execution":{"iopub.status.busy":"2021-07-02T11:19:46.117812Z","iopub.execute_input":"2021-07-02T11:19:46.118701Z","iopub.status.idle":"2021-07-02T11:19:46.133192Z","shell.execute_reply.started":"2021-07-02T11:19:46.118666Z","shell.execute_reply":"2021-07-02T11:19:46.13237Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Normalization helper function\ndef norm(x: pd.DataFrame) -> pd.DataFrame:\n    return(x - train_stats['mean'] / train_stats['std'])","metadata":{"execution":{"iopub.status.busy":"2021-07-02T11:19:46.134867Z","iopub.execute_input":"2021-07-02T11:19:46.135552Z","iopub.status.idle":"2021-07-02T11:19:46.149752Z","shell.execute_reply.started":"2021-07-02T11:19:46.135507Z","shell.execute_reply":"2021-07-02T11:19:46.149046Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def calc_entropy(col):\n    entropy = - sum([ p * math.log2(p) for p in col])\n    return entropy","metadata":{"execution":{"iopub.status.busy":"2021-07-02T11:19:46.15106Z","iopub.execute_input":"2021-07-02T11:19:46.151695Z","iopub.status.idle":"2021-07-02T11:19:46.162498Z","shell.execute_reply.started":"2021-07-02T11:19:46.151652Z","shell.execute_reply":"2021-07-02T11:19:46.161814Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data splits","metadata":{}},{"cell_type":"code","source":"raw_wine = pd.read_csv('../input/wine2csv/wine.csv')\n\n# taking a copy\ndataset = raw_wine.copy()\n\n# one hot encoding the type\nquality = dataset.pop('quality')\ndataset['quality_3'] = (quality == 3)*1.0\ndataset['quality_4'] = (quality == 4)*1.0\ndataset['quality_5'] = (quality == 5)*1.0\ndataset['quality_6'] = (quality == 6)*1.0\ndataset['quality_7'] = (quality == 7)*1.0\ndataset['quality_8'] = (quality == 8)*1.0\ndataset['quality_9'] = (quality == 9)*1.0\n\n\n# setting the X matrix and y vector.\nX_full = dataset.loc[ : , dataset.columns != 'type']\ny_full = dataset.loc[ : , dataset.columns == 'type']\n# pd.to_numeric(y_full.type) # for sparse_categorical_cross_entropy\ny_full = OneHotEncoder(sparse=False).fit_transform(dataset[[\"type\"]].values) # for categorical_cross_entropy\n\n# Model splits\nX_train, X_test, y_train, y_test = train_test_split(X_full, y_full, test_size=0.2, random_state=1903)\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=1903) # 0.25 * (1-0.2) = 0.2\n\n# bug checking splits\n# X_train, X_test, y_train, y_test = train_test_split(X_full, y_full, test_size=0.99, random_state=1903)\n# X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.25, random_state=1903) # 0.25 * (1-0.2) = 0.2\n\n# Normalizing \ntrain_stats = X_train.describe().transpose()\nX_train = norm(X_train)\nX_val = norm(X_val)\nX_test = norm(X_test)\n\n# train_set = pd.concat([X_train, y_train], axis=1)\n# test_set  = pd.concat([X_test , y_test ], axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-07-02T11:19:46.163806Z","iopub.execute_input":"2021-07-02T11:19:46.16446Z","iopub.status.idle":"2021-07-02T11:19:46.296835Z","shell.execute_reply.started":"2021-07-02T11:19:46.164418Z","shell.execute_reply":"2021-07-02T11:19:46.296139Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Epoch Levers","metadata":{}},{"cell_type":"code","source":"train_epochs = 2000\nsearch_epochs = 5\nealry_stop_pat = 200","metadata":{"execution":{"iopub.status.busy":"2021-07-02T11:19:46.29812Z","iopub.execute_input":"2021-07-02T11:19:46.298732Z","iopub.status.idle":"2021-07-02T11:19:46.303067Z","shell.execute_reply.started":"2021-07-02T11:19:46.298691Z","shell.execute_reply":"2021-07-02T11:19:46.302106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Modeling","metadata":{}},{"cell_type":"markdown","source":"## Hyper parameter tuning Helper Functions","metadata":{}},{"cell_type":"code","source":"def nll(y_true, y_pred):\n    \"\"\" Negative log likelihood. \"\"\"\n\n    # keras.losses.binary_crossentropy give the mean\n    # over the last axis. we require the sum\n    return K.sum(K.categorical_crossentropy(y_true, y_pred), axis=-1)","metadata":{"execution":{"iopub.status.busy":"2021-07-02T11:19:46.306212Z","iopub.execute_input":"2021-07-02T11:19:46.306531Z","iopub.status.idle":"2021-07-02T11:19:46.318661Z","shell.execute_reply.started":"2021-07-02T11:19:46.306503Z","shell.execute_reply":"2021-07-02T11:19:46.317722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Base","metadata":{}},{"cell_type":"code","source":"# Base model \ndef model_baseline_hp(hp):\n    K.clear_session()\n    model = keras.Sequential()\n    model.add(keras.layers.Input(shape=18)) # input layer\n    \n    # ------------------------------------------------------------\n    for i in range(hp.Int('layers', 2, 6)): # number or layers treated as a hyper parameter\n        model.add(keras.layers.Dense(hp.Int('units_' + str(i),\n                                            min_value=32,\n                                            max_value=512,\n                                            step=128),\n                                     activation=hp.Choice('act_' + str(i),\n                                                          ['relu', 'sigmoid', 'elu'])))\n        # model.add(keras.layers.Dropout(hp.Choice('drop_' + str(i), [0.2, 0.5, 0.7, 0.9])))\n    \n    # ------------------------------------------------------------\n    # model.add(keras.layers.Dense(1, activation='linear')) # output layer for regression\n    model.add(keras.layers.Dense(3, activation='softmax')) # output layer for classification\n\n    \n    # compile the model\n    optimizer = keras.optimizers.Adam(hp.Choice('learning_rate', [1e-1, 1e-2, 1e-3, 1e-4, 1e-5]))\n    model.compile(optimizer=optimizer,\n                  loss=nll,\n                  metrics=['accuracy'])\n    return model","metadata":{"execution":{"iopub.status.busy":"2021-07-02T11:19:46.320365Z","iopub.execute_input":"2021-07-02T11:19:46.320626Z","iopub.status.idle":"2021-07-02T11:19:46.332255Z","shell.execute_reply.started":"2021-07-02T11:19:46.3206Z","shell.execute_reply":"2021-07-02T11:19:46.331607Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We illustrate a Bayesian neural network with variational inference, assuming a dataset of features and labels.\n\nIt uses the Flipout gradient estimator to minimize the Kullback-Leibler divergence up to a constant, also known as the negative Evidence Lower Bound. It consists of the sum of two terms: the expected negative log-likelihood, which we approximate via Monte Carlo; and the KL divergence, which is added via regularizer terms which are arguments to the layer.\n\nReferences\n[1]: Yeming Wen, Paul Vicol, Jimmy Ba, Dustin Tran, and Roger Grosse. Flipout: Efficient Pseudo-Independent Weight Perturbations on Mini-Batches. In International Conference on Learning Representations, 2018. https://arxiv.org/abs/1803.04386\n\n","metadata":{}},{"cell_type":"markdown","source":"### Fliptout","metadata":{}},{"cell_type":"code","source":"# Bayesian model with flipout layer\ndef model_bayesian_hp_flipout(hp):\n    K.clear_session()\n    model = keras.Sequential()\n    model.add(keras.layers.Input(shape=18)) # input layer\n    model.add(tfp.layers.DenseFlipout(hp.Int('flip_units',\n                                                 min_value=32,\n                                                 max_value=512,\n                                                 step=128),\n                                          activation=hp.Choice('flip_act', ['relu', 'sigmoid', 'elu'])))\n    \n    # -------------------------------------------------------------------------------------------\n    for i in range(hp.Int('layers', 2, 8)): # number or layers treated as a hyper parameter\n        model.add(keras.layers.Dense(hp.Int('units_' + str(i),\n                                            min_value=32,\n                                            max_value=512,\n                                            step=128),\n                                     activation=hp.Choice('act_' + str(i),\n                                                          ['relu', 'sigmoid', 'elu'])))\n        # model.add(keras.layers.Dropout(hp.Choice('drop_' + str(i), [0.2, 0.5, 0.7, 0.9])))\n    # -------------------------------------------------------------------------------------------\n    \n    # model.add(keras.layers.Dense(1, activation='linear')) # output layer for regression\n    model.add(tfp.layers.DenseFlipout(3, activation='softmax')) # output layer for classification\n\n    \n    # compile the model\n    optimizer = keras.optimizers.Adam(hp.Choice('learning_rate', [1e-3, 1e-4, 1e-5, 1e-6, 1e-7, 1e-8]))\n    model.compile(optimizer=optimizer,\n                  loss=nll,\n                  metrics=['accuracy'])\n    return model","metadata":{"execution":{"iopub.status.busy":"2021-07-02T11:19:46.333264Z","iopub.execute_input":"2021-07-02T11:19:46.333672Z","iopub.status.idle":"2021-07-02T11:19:46.348734Z","shell.execute_reply.started":"2021-07-02T11:19:46.333644Z","shell.execute_reply":"2021-07-02T11:19:46.348011Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"------------------\n### Variational","metadata":{}},{"cell_type":"code","source":"# Multivariate Normal zero one prior\ndef prior_trainable(kernel_size: int, bias_size: int, dtype: Any) -> tf.keras.Model:\n    n = kernel_size + bias_size\n    return tf.keras.Sequential([\n        tfp.layers.VariableLayer(n, dtype=dtype),\n        tfp.layers.DistributionLambda(lambda t: tfd.Independent(\n            tfd.Normal(loc=t, scale=1),\n            reinterpreted_batch_ndims=1)),\n    ])\n\n# Therefore, theory tells us that the posterior is also Multivariate Normal\ndef posterior_mean_field(kernel_size: int, bias_size: int, dtype: Any) -> tf.keras.Model:\n    n = kernel_size + bias_size\n    c = np.log(np.expm1(1.))\n    \n    return tf.keras.Sequential([\n        tfp.layers.VariableLayer(2 * n, dtype=dtype),\n        tfp.layers.DistributionLambda(lambda t: tfd.Independent(\n            tfd.Normal(loc=t[..., :n],\n                      scale=1e-5 + tf.nn.softplus(c + t[..., n:])),\n        reinterpreted_batch_ndims=1)),\n    ])","metadata":{"execution":{"iopub.status.busy":"2021-07-02T11:19:46.349787Z","iopub.execute_input":"2021-07-02T11:19:46.350225Z","iopub.status.idle":"2021-07-02T11:19:46.365037Z","shell.execute_reply.started":"2021-07-02T11:19:46.350188Z","shell.execute_reply":"2021-07-02T11:19:46.364335Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Bayesian model with variational layer \ndef model_bayesian_hp_variational(hp):\n    K.clear_session()\n    model = keras.Sequential()\n    model.add(tfp.layers.DenseVariational(hp.Int('var_units',\n                                                 min_value=32,\n                                                 max_value=512,\n                                                 step=128),\n                                          activation=hp.Choice('var_act', ['relu', 'sigmoid', 'elu']),\n                                          input_shape=[len(X_train.keys())],\n                                          make_posterior_fn=posterior_mean_field, \n                                          make_prior_fn=prior_trainable, \n                                          kl_weight=1/X_train.shape[0]))\n\n    # -------------------------------------------------------------------------------------------\n    for i in range(hp.Int('layers', 2, 6)): # number or layers treated as a hyper parameter\n        model.add(keras.layers.Dense(hp.Int('units_' + str(i),\n                                            min_value=32,\n                                            max_value=512,\n                                            step=128),\n                                     activation=hp.Choice('act_' + str(i),\n                                                          ['relu', 'sigmoid', 'elu'])))\n        # model.add(keras.layers.Dropout(hp.Choice('drop_' + str(i), [0.2, 0.5, 0.7, 0.9])))\n    # -------------------------------------------------------------------------------------------\n\n    # model.add(keras.layers.Dense(1, activation='linear')) # output layer for regression\n    model.add(keras.layers.Dense(3, activation='softmax')) # output layer for classification ## \n\n\n    # compile the model\n    optimizer = keras.optimizers.Adam(hp.Choice('learning_rate', [1e-3, 1e-4, 1e-5, 1e-6, 1e-7]))\n    model.compile(optimizer=optimizer,\n                  loss=nll,\n                  metrics=['accuracy'])\n    return model","metadata":{"execution":{"iopub.status.busy":"2021-07-02T11:19:46.366062Z","iopub.execute_input":"2021-07-02T11:19:46.366469Z","iopub.status.idle":"2021-07-02T11:19:46.383403Z","shell.execute_reply.started":"2021-07-02T11:19:46.36644Z","shell.execute_reply":"2021-07-02T11:19:46.382775Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Overwrite the Dropout layer\nclass MCDropout(Dropout):\n    def call(self, inputs):\n        return super().call(inputs, training=True)","metadata":{"execution":{"iopub.status.busy":"2021-07-02T11:19:46.384355Z","iopub.execute_input":"2021-07-02T11:19:46.384775Z","iopub.status.idle":"2021-07-02T11:19:46.400573Z","shell.execute_reply.started":"2021-07-02T11:19:46.384747Z","shell.execute_reply":"2021-07-02T11:19:46.399698Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# MCdropout layer model \ndef model_mcdropout_hp(hp):\n    K.clear_session()\n    model = keras.Sequential()\n    model.add(keras.layers.Input(shape=18)) # input layer\n    \n    # ------------------------------------------------------------\n    for i in range(hp.Int('layers', 2, 6)): # number or layers treated as a hyper parameter\n        model.add(keras.layers.Dense(hp.Int('units_' + str(i),\n                                            min_value=32,\n                                            max_value=512,\n                                            step=128),\n                                     activation=hp.Choice('act_' + str(i),\n                                                          ['relu', 'sigmoid', 'elu'])))\n        model.add(MCDropout(hp.Choice('mcdrop_' + str(i), [0.3, 0.5, 0.7, 0.9])))\n    \n    # ------------------------------------------------------------\n    # model.add(keras.layers.Dense(1, activation='linear')) # output layer for regression\n    model.add(keras.layers.Dense(3, activation='softmax')) # output layer for classification\n\n    \n    # compile the model\n    optimizer = keras.optimizers.Adam(hp.Choice('learning_rate', [1e-1, 1e-2, 1e-3, 1e-4, 1e-5]))\n    model.compile(optimizer=optimizer,\n                  loss=nll,\n                  metrics=['accuracy'])\n    return model","metadata":{"execution":{"iopub.status.busy":"2021-07-02T11:19:46.403221Z","iopub.execute_input":"2021-07-02T11:19:46.403512Z","iopub.status.idle":"2021-07-02T11:19:46.416467Z","shell.execute_reply.started":"2021-07-02T11:19:46.403487Z","shell.execute_reply":"2021-07-02T11:19:46.415632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"------------------------\n### Base model","metadata":{}},{"cell_type":"code","source":"tuner = RandomSearch(model_baseline_hp,\n                     objective='val_accuracy',\n                     max_trials=10,\n                     executions_per_trial=2,\n                     directory='rand_search_outputs',\n                     project_name='base_model')\ntuner.search_space_summary()","metadata":{"execution":{"iopub.status.busy":"2021-07-02T11:19:46.418154Z","iopub.execute_input":"2021-07-02T11:19:46.418412Z","iopub.status.idle":"2021-07-02T11:19:46.739532Z","shell.execute_reply.started":"2021-07-02T11:19:46.418385Z","shell.execute_reply":"2021-07-02T11:19:46.737934Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tuner.search(X_train, y_train, epochs=search_epochs,\n             validation_data=(X_val, y_val))\ntuner.results_summary()","metadata":{"execution":{"iopub.status.busy":"2021-07-02T11:19:46.740679Z","iopub.execute_input":"2021-07-02T11:19:46.740919Z","iopub.status.idle":"2021-07-02T11:20:34.782279Z","shell.execute_reply.started":"2021-07-02T11:19:46.740894Z","shell.execute_reply":"2021-07-02T11:20:34.781422Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tuner.get_best_hyperparameters()[0].values","metadata":{"execution":{"iopub.status.busy":"2021-07-02T11:20:34.783709Z","iopub.execute_input":"2021-07-02T11:20:34.784175Z","iopub.status.idle":"2021-07-02T11:20:34.792613Z","shell.execute_reply.started":"2021-07-02T11:20:34.784132Z","shell.execute_reply":"2021-07-02T11:20:34.791475Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_base_model = tuner.get_best_models()[0]","metadata":{"execution":{"iopub.status.busy":"2021-07-02T11:20:34.794297Z","iopub.execute_input":"2021-07-02T11:20:34.794707Z","iopub.status.idle":"2021-07-02T11:20:35.105862Z","shell.execute_reply.started":"2021-07-02T11:20:34.794668Z","shell.execute_reply":"2021-07-02T11:20:35.105022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"early_stop = keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=ealry_stop_pat)","metadata":{"execution":{"iopub.status.busy":"2021-07-02T11:20:35.106993Z","iopub.execute_input":"2021-07-02T11:20:35.107232Z","iopub.status.idle":"2021-07-02T11:20:35.111321Z","shell.execute_reply.started":"2021-07-02T11:20:35.107208Z","shell.execute_reply":"2021-07-02T11:20:35.110079Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history_base = best_base_model.fit(x=X_train,\n                                   y=y_train,\n                                   epochs=train_epochs,\n                                   batch_size=len(X_train),\n                                   verbose=0,\n                                   validation_split=0.2,\n                                   callbacks=[early_stop])","metadata":{"execution":{"iopub.status.busy":"2021-07-02T11:20:35.112569Z","iopub.execute_input":"2021-07-02T11:20:35.112808Z","iopub.status.idle":"2021-07-02T11:20:48.18394Z","shell.execute_reply.started":"2021-07-02T11:20:35.112784Z","shell.execute_reply":"2021-07-02T11:20:48.18299Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"------------------------\n### Variational","metadata":{}},{"cell_type":"code","source":"tuner_var = RandomSearch(model_bayesian_hp_variational,\n                     objective='val_accuracy',\n                     max_trials=10,\n                     executions_per_trial=2,\n                     directory='rand_search_outputs',\n                     project_name='variational_model')\ntuner_var.search_space_summary()","metadata":{"execution":{"iopub.status.busy":"2021-07-02T11:20:48.185489Z","iopub.execute_input":"2021-07-02T11:20:48.185861Z","iopub.status.idle":"2021-07-02T11:20:48.692218Z","shell.execute_reply.started":"2021-07-02T11:20:48.185819Z","shell.execute_reply":"2021-07-02T11:20:48.691311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tuner_var.search(X_train, y_train, epochs=search_epochs,\n             validation_data=(X_val, y_val))\ntuner_var.results_summary()","metadata":{"execution":{"iopub.status.busy":"2021-07-02T11:20:48.69333Z","iopub.execute_input":"2021-07-02T11:20:48.693589Z","iopub.status.idle":"2021-07-02T11:22:05.203879Z","shell.execute_reply.started":"2021-07-02T11:20:48.693562Z","shell.execute_reply":"2021-07-02T11:22:05.202838Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tuner_var.get_best_hyperparameters()[0].values","metadata":{"execution":{"iopub.status.busy":"2021-07-02T11:22:05.208494Z","iopub.execute_input":"2021-07-02T11:22:05.208796Z","iopub.status.idle":"2021-07-02T11:22:05.214784Z","shell.execute_reply.started":"2021-07-02T11:22:05.208767Z","shell.execute_reply":"2021-07-02T11:22:05.213774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_var_model = tuner_var.get_best_models()[0]","metadata":{"execution":{"iopub.status.busy":"2021-07-02T11:22:05.21664Z","iopub.execute_input":"2021-07-02T11:22:05.216936Z","iopub.status.idle":"2021-07-02T11:22:05.878561Z","shell.execute_reply.started":"2021-07-02T11:22:05.216889Z","shell.execute_reply":"2021-07-02T11:22:05.877582Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history_var = best_var_model.fit(x=X_train,\n                                 y=y_train,\n                                 epochs=train_epochs,\n                                 batch_size=32,\n                                 verbose=0,\n                                 validation_split=0.2,\n                                 callbacks=[early_stop])","metadata":{"execution":{"iopub.status.busy":"2021-07-02T11:22:05.880073Z","iopub.execute_input":"2021-07-02T11:22:05.880503Z","iopub.status.idle":"2021-07-02T11:26:41.510431Z","shell.execute_reply.started":"2021-07-02T11:22:05.880464Z","shell.execute_reply":"2021-07-02T11:26:41.509565Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"------------------------\n### Flipout","metadata":{}},{"cell_type":"code","source":"tuner_flip = RandomSearch(model_bayesian_hp_flipout,\n                     objective='val_accuracy',\n                     max_trials=10,\n                     executions_per_trial=2,\n                     directory='rand_search_outputs',\n                     project_name='fliptout_model')\ntuner_flip.search_space_summary()","metadata":{"execution":{"iopub.status.busy":"2021-07-02T11:26:41.511824Z","iopub.execute_input":"2021-07-02T11:26:41.512223Z","iopub.status.idle":"2021-07-02T11:26:41.887544Z","shell.execute_reply.started":"2021-07-02T11:26:41.512183Z","shell.execute_reply":"2021-07-02T11:26:41.886553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tuner_flip.search(X_train, y_train, epochs=search_epochs,\n             validation_data=(X_val, y_val))\ntuner_flip.results_summary()","metadata":{"execution":{"iopub.status.busy":"2021-07-02T11:26:41.88862Z","iopub.execute_input":"2021-07-02T11:26:41.888868Z","iopub.status.idle":"2021-07-02T11:28:09.716112Z","shell.execute_reply.started":"2021-07-02T11:26:41.888843Z","shell.execute_reply":"2021-07-02T11:28:09.715155Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tuner_flip.get_best_hyperparameters()[0].values","metadata":{"execution":{"iopub.status.busy":"2021-07-02T11:28:09.717587Z","iopub.execute_input":"2021-07-02T11:28:09.718051Z","iopub.status.idle":"2021-07-02T11:28:09.724444Z","shell.execute_reply.started":"2021-07-02T11:28:09.71801Z","shell.execute_reply":"2021-07-02T11:28:09.722801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_flip_model = tuner_flip.get_best_models()[0]","metadata":{"execution":{"iopub.status.busy":"2021-07-02T11:28:09.725436Z","iopub.execute_input":"2021-07-02T11:28:09.72567Z","iopub.status.idle":"2021-07-02T11:28:10.258641Z","shell.execute_reply.started":"2021-07-02T11:28:09.725647Z","shell.execute_reply":"2021-07-02T11:28:10.257613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history_flip = best_flip_model.fit(x=X_train,\n                    y=y_train,\n                    epochs=train_epochs,\n                    batch_size=len(X_train),\n                    verbose=0,\n                    validation_split=0.2,\n                    callbacks=[early_stop])","metadata":{"execution":{"iopub.status.busy":"2021-07-02T11:28:10.259804Z","iopub.execute_input":"2021-07-02T11:28:10.26013Z","iopub.status.idle":"2021-07-02T11:30:59.323421Z","shell.execute_reply.started":"2021-07-02T11:28:10.2601Z","shell.execute_reply":"2021-07-02T11:30:59.322269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"----------------------\n### MCDropout","metadata":{}},{"cell_type":"code","source":"tuner_mcdrop = RandomSearch(model_mcdropout_hp,\n                     objective='val_accuracy',\n                     max_trials=10,\n                     executions_per_trial=2,\n                     directory='rand_search_outputs',\n                     project_name='mcdrop_model')\ntuner_mcdrop.search_space_summary()","metadata":{"execution":{"iopub.status.busy":"2021-07-02T11:30:59.328376Z","iopub.execute_input":"2021-07-02T11:30:59.328685Z","iopub.status.idle":"2021-07-02T11:30:59.697298Z","shell.execute_reply.started":"2021-07-02T11:30:59.328657Z","shell.execute_reply":"2021-07-02T11:30:59.696239Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tuner_mcdrop.search(X_train, y_train, epochs=search_epochs,\n             validation_data=(X_val, y_val))\ntuner_mcdrop.results_summary()","metadata":{"execution":{"iopub.status.busy":"2021-07-02T11:30:59.69879Z","iopub.execute_input":"2021-07-02T11:30:59.699185Z","iopub.status.idle":"2021-07-02T11:31:51.935408Z","shell.execute_reply.started":"2021-07-02T11:30:59.699144Z","shell.execute_reply":"2021-07-02T11:31:51.934288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tuner_mcdrop.get_best_hyperparameters()[0].values","metadata":{"execution":{"iopub.status.busy":"2021-07-02T11:31:51.938388Z","iopub.execute_input":"2021-07-02T11:31:51.938646Z","iopub.status.idle":"2021-07-02T11:31:51.943703Z","shell.execute_reply.started":"2021-07-02T11:31:51.93862Z","shell.execute_reply":"2021-07-02T11:31:51.943069Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_mcdrop_model = tuner_mcdrop.get_best_models()[0]","metadata":{"execution":{"iopub.status.busy":"2021-07-02T11:31:51.944642Z","iopub.execute_input":"2021-07-02T11:31:51.944904Z","iopub.status.idle":"2021-07-02T11:31:52.290584Z","shell.execute_reply.started":"2021-07-02T11:31:51.94487Z","shell.execute_reply":"2021-07-02T11:31:52.289595Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history_mcdrop = best_mcdrop_model.fit(x=X_train,\n                                       y=y_train,\n                                       epochs=train_epochs,\n                                       batch_size=len(X_train),\n                                       verbose=0,\n                                       validation_split=0.2,\n                                       callbacks=[early_stop])","metadata":{"execution":{"iopub.status.busy":"2021-07-02T11:31:52.291708Z","iopub.execute_input":"2021-07-02T11:31:52.291945Z","iopub.status.idle":"2021-07-02T11:32:39.672373Z","shell.execute_reply.started":"2021-07-02T11:31:52.29192Z","shell.execute_reply":"2021-07-02T11:32:39.671467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Histories","metadata":{}},{"cell_type":"code","source":"best_base_model.summary()","metadata":{"execution":{"iopub.status.busy":"2021-07-02T11:32:39.673632Z","iopub.execute_input":"2021-07-02T11:32:39.673907Z","iopub.status.idle":"2021-07-02T11:32:39.681004Z","shell.execute_reply.started":"2021-07-02T11:32:39.67388Z","shell.execute_reply":"2021-07-02T11:32:39.680296Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hist = pd.DataFrame(history_base.history)\nhist['epoch'] = history_base.epoch\nplot_history(hist, title='Base Model History', file_title='a.history-base.pdf')","metadata":{"execution":{"iopub.status.busy":"2021-07-02T11:32:39.681904Z","iopub.execute_input":"2021-07-02T11:32:39.682298Z","iopub.status.idle":"2021-07-02T11:32:39.988059Z","shell.execute_reply.started":"2021-07-02T11:32:39.68227Z","shell.execute_reply":"2021-07-02T11:32:39.98707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_var_model.summary()","metadata":{"execution":{"iopub.status.busy":"2021-07-02T11:32:39.989502Z","iopub.execute_input":"2021-07-02T11:32:39.989882Z","iopub.status.idle":"2021-07-02T11:32:40.001502Z","shell.execute_reply.started":"2021-07-02T11:32:39.989841Z","shell.execute_reply":"2021-07-02T11:32:40.000016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hist = pd.DataFrame(history_var.history)\nhist['epoch'] = history_var.epoch\nh2 = plot_history(hist, title='Variational Layer Model History', file_title='b.history-var.pdf')","metadata":{"execution":{"iopub.status.busy":"2021-07-02T11:32:40.003089Z","iopub.execute_input":"2021-07-02T11:32:40.003488Z","iopub.status.idle":"2021-07-02T11:32:40.282394Z","shell.execute_reply.started":"2021-07-02T11:32:40.003447Z","shell.execute_reply":"2021-07-02T11:32:40.281417Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_flip_model.summary()","metadata":{"execution":{"iopub.status.busy":"2021-07-02T11:32:40.283775Z","iopub.execute_input":"2021-07-02T11:32:40.284191Z","iopub.status.idle":"2021-07-02T11:32:40.293722Z","shell.execute_reply.started":"2021-07-02T11:32:40.284147Z","shell.execute_reply":"2021-07-02T11:32:40.292812Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hist_flip = pd.DataFrame(history_flip.history)\nhist_flip['epoch'] = history_flip.epoch\nh3 = plot_history(hist_flip, title='Flipout layer History', file_title='c.history-flip.pdf')","metadata":{"execution":{"iopub.status.busy":"2021-07-02T11:32:40.295007Z","iopub.execute_input":"2021-07-02T11:32:40.295306Z","iopub.status.idle":"2021-07-02T11:32:40.559877Z","shell.execute_reply.started":"2021-07-02T11:32:40.295277Z","shell.execute_reply":"2021-07-02T11:32:40.558934Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_mcdrop_model.summary()","metadata":{"execution":{"iopub.status.busy":"2021-07-02T11:32:40.561017Z","iopub.execute_input":"2021-07-02T11:32:40.561313Z","iopub.status.idle":"2021-07-02T11:32:40.567642Z","shell.execute_reply.started":"2021-07-02T11:32:40.561286Z","shell.execute_reply":"2021-07-02T11:32:40.5668Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hist_mcdrop = pd.DataFrame(history_mcdrop.history)\nhist_mcdrop['epoch'] = history_mcdrop.epoch\nh4 = plot_history(hist_mcdrop, title='MCdropout layer History', file_title='d.history-mcdrop.pdf')","metadata":{"execution":{"iopub.status.busy":"2021-07-02T11:32:40.568776Z","iopub.execute_input":"2021-07-02T11:32:40.569053Z","iopub.status.idle":"2021-07-02T11:32:40.808286Z","shell.execute_reply.started":"2021-07-02T11:32:40.569026Z","shell.execute_reply":"2021-07-02T11:32:40.807243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Validation","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\n\np_base = best_base_model.predict(X_val)\ncf_mat_base = confusion_matrix(np.argmax(y_val, axis=1),\n                 np.argmax(p_base, axis=1))\nplot_confusion_matrix(cf_mat_base, class_labels=[1, 2, 3], file_title='e.confmat-base.pdf')","metadata":{"execution":{"iopub.status.busy":"2021-07-02T11:32:40.809719Z","iopub.execute_input":"2021-07-02T11:32:40.810015Z","iopub.status.idle":"2021-07-02T11:32:41.290038Z","shell.execute_reply.started":"2021-07-02T11:32:40.809983Z","shell.execute_reply":"2021-07-02T11:32:41.289123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"p_var = best_var_model.predict(X_val)\ncf_mat_var = confusion_matrix(np.argmax(y_val, axis=1),\n                 np.argmax(p_var, axis=1))\nplot_confusion_matrix(cf_mat_var, class_labels=[1, 2, 3], file_title='f.confmat-var.pdf')","metadata":{"execution":{"iopub.status.busy":"2021-07-02T11:32:41.291147Z","iopub.execute_input":"2021-07-02T11:32:41.291391Z","iopub.status.idle":"2021-07-02T11:32:41.803822Z","shell.execute_reply.started":"2021-07-02T11:32:41.291366Z","shell.execute_reply":"2021-07-02T11:32:41.802759Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"p_flip = best_flip_model.predict(X_val)\ncf_mat_flip = confusion_matrix(np.argmax(y_val, axis=1),\n                 np.argmax(p_flip, axis=1))\nplot_confusion_matrix(cf_mat_flip, class_labels=[1, 2, 3], file_title='g.confmat-flip.pdf')","metadata":{"execution":{"iopub.status.busy":"2021-07-02T11:32:41.804943Z","iopub.execute_input":"2021-07-02T11:32:41.805226Z","iopub.status.idle":"2021-07-02T11:32:42.399601Z","shell.execute_reply.started":"2021-07-02T11:32:41.805191Z","shell.execute_reply":"2021-07-02T11:32:42.398705Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"p_mcdrop = best_mcdrop_model.predict(X_val)\ncf_mat_mcdrop = confusion_matrix(np.argmax(y_val, axis=1), \n                                 np.argmax(p_mcdrop, axis=1))\nplot_confusion_matrix(cf_mat_mcdrop, class_labels=[1, 2, 3], file_title='h.confmat-mcdrop.pdf')","metadata":{"execution":{"iopub.status.busy":"2021-07-02T11:32:42.400788Z","iopub.execute_input":"2021-07-02T11:32:42.401073Z","iopub.status.idle":"2021-07-02T11:32:42.783505Z","shell.execute_reply.started":"2021-07-02T11:32:42.401044Z","shell.execute_reply":"2021-07-02T11:32:42.782455Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The traditional NN works better, but within the Bayesian approaches, the MCdropout works best","metadata":{}},{"cell_type":"markdown","source":"# Model Explanation","metadata":{}},{"cell_type":"code","source":"# Select the best model for the analysis\nmodel = best_mcdrop_model","metadata":{"execution":{"iopub.status.busy":"2021-07-02T11:32:42.784856Z","iopub.execute_input":"2021-07-02T11:32:42.785152Z","iopub.status.idle":"2021-07-02T11:32:42.789117Z","shell.execute_reply.started":"2021-07-02T11:32:42.785123Z","shell.execute_reply":"2021-07-02T11:32:42.788133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# calculate SHAP values\nexplainer = shap.KernelExplainer(model.predict, X_test)\nshap_values = explainer.shap_values(X_test, nsamples=100)","metadata":{"execution":{"iopub.status.busy":"2021-07-01T11:38:16.978742Z","iopub.execute_input":"2021-07-01T11:38:16.979077Z","iopub.status.idle":"2021-07-01T14:33:22.541736Z","shell.execute_reply.started":"2021-07-01T11:38:16.979048Z","shell.execute_reply":"2021-07-01T14:33:22.540873Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot summary\nshap.summary_plot(shap_values, X_test, feature_names=X_test.columns, plot_type=\"bar\", show=False)\nplt.savefig('i.shap-summary.pdf', dpi=500)","metadata":{"execution":{"iopub.status.busy":"2021-07-01T14:33:22.543898Z","iopub.execute_input":"2021-07-01T14:33:22.544666Z","iopub.status.idle":"2021-07-01T14:33:23.218617Z","shell.execute_reply.started":"2021-07-01T14:33:22.544597Z","shell.execute_reply":"2021-07-01T14:33:23.217525Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot Summary for class 0\nshap.summary_plot(shap_values[0], X_test, feature_names=X_test.columns, show=False)\nplt.savefig('j.shap-class0.pdf', dpi=500)","metadata":{"execution":{"iopub.status.busy":"2021-07-01T14:33:23.222133Z","iopub.execute_input":"2021-07-01T14:33:23.222467Z","iopub.status.idle":"2021-07-01T14:33:25.673992Z","shell.execute_reply.started":"2021-07-01T14:33:23.222435Z","shell.execute_reply":"2021-07-01T14:33:25.672757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot Summary for class 1\nshap.summary_plot(shap_values[1], X_test, feature_names=X_test.columns, show=False)\nplt.savefig('k.shap-class1.pdf', dpi=500)","metadata":{"execution":{"iopub.status.busy":"2021-07-01T14:33:25.675447Z","iopub.execute_input":"2021-07-01T14:33:25.675798Z","iopub.status.idle":"2021-07-01T14:33:28.005374Z","shell.execute_reply.started":"2021-07-01T14:33:25.675765Z","shell.execute_reply":"2021-07-01T14:33:28.004175Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot Summary for class 2\nshap.summary_plot(shap_values[2], X_test, feature_names=X_test.columns, show=False)\nplt.savefig('l.shap-class2.pdf', dpi=500)","metadata":{"execution":{"iopub.status.busy":"2021-07-01T14:33:28.007209Z","iopub.execute_input":"2021-07-01T14:33:28.007589Z","iopub.status.idle":"2021-07-01T14:33:30.272512Z","shell.execute_reply.started":"2021-07-01T14:33:28.007552Z","shell.execute_reply":"2021-07-01T14:33:30.27166Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# MCMC Sampling","metadata":{}},{"cell_type":"markdown","source":"https://github.com/zacharyaanglin/ProbabilisticDeepLearningTensorFlow/blob/master/2%20-%20Simple%20linear%20regression%20in%20Keras%20with%20uncertainty.ipynb\n\nhttps://colab.research.google.com/drive/149Wg0uB0x1ZrPDMme8gyOnlsgHC9JM6M?hl=en&pli=1#scrollTo=Bxhbrf1R1UPE","metadata":{}},{"cell_type":"code","source":"# draw predictions n times\nn_samples = 1000\nyhats = [model.predict(X_test) for _ in range(n_samples)]\nn_set = X_test.shape[0]","metadata":{"execution":{"iopub.status.busy":"2021-07-02T11:32:42.790267Z","iopub.execute_input":"2021-07-02T11:32:42.79052Z","iopub.status.idle":"2021-07-02T11:33:45.651716Z","shell.execute_reply.started":"2021-07-02T11:32:42.790486Z","shell.execute_reply":"2021-07-02T11:33:45.650808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# fix format of output\nyhat_samples = pd.DataFrame(list(itertools.chain.from_iterable(yhats)))","metadata":{"execution":{"iopub.status.busy":"2021-07-02T11:33:45.653206Z","iopub.execute_input":"2021-07-02T11:33:45.65361Z","iopub.status.idle":"2021-07-02T11:33:48.020941Z","shell.execute_reply.started":"2021-07-02T11:33:45.65357Z","shell.execute_reply":"2021-07-02T11:33:48.020031Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# fix format of output\nyhat_samples = []\nfor i in range(n_samples):\n    yhat_samples.extend(yhats[i])\nyhat_samples = pd.DataFrame(yhat_samples)","metadata":{"execution":{"iopub.status.busy":"2021-07-02T11:33:48.031673Z","iopub.execute_input":"2021-07-02T11:33:48.031989Z","iopub.status.idle":"2021-07-02T11:33:50.048341Z","shell.execute_reply.started":"2021-07-02T11:33:48.031944Z","shell.execute_reply":"2021-07-02T11:33:50.047368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create id columns for validation number and sample number\nid_col = list(range(n_set)) # validation set number\nsamples_col = np.repeat(np.arange(n_samples), n_set, axis=0) # sample number","metadata":{"execution":{"iopub.status.busy":"2021-07-02T11:33:50.05024Z","iopub.execute_input":"2021-07-02T11:33:50.050621Z","iopub.status.idle":"2021-07-02T11:33:50.058879Z","shell.execute_reply.started":"2021-07-02T11:33:50.05059Z","shell.execute_reply":"2021-07-02T11:33:50.057976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# add extra columns and format\nyhat_samples[\"id\"] = id_col*n_samples\nid_col = yhat_samples.pop(\"id\")\nyhat_samples.insert(0, \"val_id\", id_col)\nyhat_samples.insert(1, \"sam_id\", samples_col)\nyhat_samples.insert(5, \"true_1\", pd.DataFrame(list(y_val)*n_samples)[0])\nyhat_samples.insert(6, \"true_2\", pd.DataFrame(list(y_val)*n_samples)[1])\nyhat_samples.insert(7, \"true_3\", pd.DataFrame(list(y_val)*n_samples)[2])\nyhat_samples.columns = ['val_id', 'sam_id', 'pred_1', 'pred_2', 'pred_3', 'true_1', 'true_2', 'true_3'] # rename column names","metadata":{"execution":{"iopub.status.busy":"2021-07-02T11:33:50.06054Z","iopub.execute_input":"2021-07-02T11:33:50.06092Z","iopub.status.idle":"2021-07-02T11:33:55.245492Z","shell.execute_reply.started":"2021-07-02T11:33:50.060879Z","shell.execute_reply":"2021-07-02T11:33:55.244543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# yhat_samples['Entropy'] = -(values*np.log(values))\nentropies = pd.DataFrame(yhat_samples.groupby('val_id')[['pred_1', 'pred_2', 'pred_3', 'true_1', 'true_2', 'true_3']].mean())\nshannon = entropies.loc[:,'pred_1':'pred_3'].apply(calc_entropy,axis=1)\nentropies['entropy'] = shannon\ntop_10 = entropies.sort_values(\"entropy\", ascending=False).head(5)\ntop_10_inx = top_10.index\ntop_10","metadata":{"execution":{"iopub.status.busy":"2021-07-02T13:34:19.8172Z","iopub.execute_input":"2021-07-02T13:34:19.817621Z","iopub.status.idle":"2021-07-02T13:34:19.884363Z","shell.execute_reply.started":"2021-07-02T13:34:19.817573Z","shell.execute_reply":"2021-07-02T13:34:19.883374Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"confidence = yhat_samples >> group_by(_.val_id) >> mutate(avg_1 = _.pred_1.mean(),\n                                                          avg_2 = _.pred_2.mean(),\n                                                          avg_3 = _.pred_3.mean(),\n                                                          std_1 = _.pred_1.std(),\n                                                          std_2 = _.pred_2.std(),\n                                                          std_3 = _.pred_3.std(),\n                                                          ci_95_l_1 = _.avg_1-1.96*_.pred_1.std()/math.sqrt(n_samples),\n                                                          ci_95_h_1 = _.avg_1+1.96*_.pred_2.std()/math.sqrt(n_samples),\n                                                          ci_95_l_2 = _.avg_2-1.96*_.pred_3.std()/math.sqrt(n_samples),\n                                                          ci_95_h_2 = _.avg_2+1.96*_.pred_1.std()/math.sqrt(n_samples),\n                                                          ci_95_l_3 = _.avg_3-1.96*_.pred_2.std()/math.sqrt(n_samples),\n                                                          ci_95_h_3 = _.avg_3+1.96*_.pred_3.std()/math.sqrt(n_samples),\n                                                          diff_ci_1 = _.ci_95_h_1 - _.ci_95_l_1,\n                                                          diff_ci_2 = _.ci_95_h_2 - _.ci_95_l_2,\n                                                          diff_ci_3 = _.ci_95_h_3 - _.ci_95_l_3) >> filter(_.sam_id==0)\n","metadata":{"execution":{"iopub.status.busy":"2021-07-02T12:16:44.179598Z","iopub.execute_input":"2021-07-02T12:16:44.179987Z","iopub.status.idle":"2021-07-02T12:16:58.20931Z","shell.execute_reply.started":"2021-07-02T12:16:44.179924Z","shell.execute_reply":"2021-07-02T12:16:58.208486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_ci = confidence[['true_1', 'true_2', 'true_3',\n                      'avg_1', 'avg_2', 'avg_3',\n                      'ci_95_l_1', 'ci_95_h_1',\n                      'ci_95_l_2', 'ci_95_h_2',\n                      'ci_95_l_3', 'ci_95_h_3',\n                      'std_1', 'std_2', 'std_3',\n                      'diff_ci_1', 'diff_ci_2', 'diff_ci_3']]\npred_ci >> arrange(-_.diff_ci_2)","metadata":{"execution":{"iopub.status.busy":"2021-07-02T13:29:10.470472Z","iopub.execute_input":"2021-07-02T13:29:10.470859Z","iopub.status.idle":"2021-07-02T13:29:10.493878Z","shell.execute_reply.started":"2021-07-02T13:29:10.470819Z","shell.execute_reply":"2021-07-02T13:29:10.493067Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Function for entropy as anomaly measure","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}